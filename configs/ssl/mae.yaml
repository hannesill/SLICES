# @package ssl
# MAE (Masked Autoencoder) SSL Configuration
#
# Observation-level tokenization: each token = one observed (timestep, feature, value).
# Encoder processes only visible tokens (25%). Decoder reconstructs masked tokens.
# No MISSING_TOKEN needed -- missingness is handled intrinsically by only
# tokenizing observed values.

name: mae

# Masking parameters
mask_ratio: 0.75  # Fraction of observation tokens to mask (original MAE default)

# Decoder parameters (lighter than encoder)
decoder_d_model: 128  # Decoder hidden dimension
decoder_n_layers: 2   # Number of decoder transformer layers
decoder_n_heads: 4    # Number of decoder attention heads
decoder_d_ff: 512     # Decoder feedforward dimension
decoder_dropout: 0.1
